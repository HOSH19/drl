{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watch Trained Agent Play Snake\n",
    "\n",
    "Load a trained model and watch it play the game in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "from environments import SnakeEnv\n",
    "from agents import DQNAgent, PPODiscreteAgent\n",
    "import yaml\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config_path = '../configs/snake_config.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Config loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "env = SnakeEnv(\n",
    "    grid_size=config['environment']['grid_size'],\n",
    "    state_representation=config['environment']['state_representation'],\n",
    "    initial_length=config['environment']['initial_length'],\n",
    "    reward_food=config['environment']['reward_food'],\n",
    "    reward_death=config['environment']['reward_death'],\n",
    "    reward_step=config['environment']['reward_step'],\n",
    "    reward_distance=config['environment']['reward_distance'],\n",
    "    render_mode=None  # We'll render manually\n",
    ")\n",
    "\n",
    "# Get state shape\n",
    "obs_space = env.observation_space\n",
    "if hasattr(obs_space, 'shape'):\n",
    "    state_shape = obs_space.shape\n",
    "else:\n",
    "    state_shape = (obs_space.n,)\n",
    "\n",
    "print(f\"Environment created! State shape: {state_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained agent\n",
    "# Update this path to your checkpoint\n",
    "checkpoint_path = '../checkpoints/snake/best_model.pth'  # or 'final_model.pth'\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    print(f\"⚠️  Checkpoint not found at {checkpoint_path}\")\n",
    "    print(\"Available checkpoints:\")\n",
    "    checkpoint_dir = '../checkpoints/snake'\n",
    "    if os.path.exists(checkpoint_dir):\n",
    "        for f in os.listdir(checkpoint_dir):\n",
    "            if f.endswith('.pth'):\n",
    "                print(f\"  - {os.path.join(checkpoint_dir, f)}\")\n",
    "    checkpoint_path = input(\"Enter checkpoint path: \") or checkpoint_path\n",
    "\n",
    "# Create agent\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "algorithm = config['training']['algorithm'].lower()\n",
    "\n",
    "if algorithm == \"dqn\":\n",
    "    agent = DQNAgent(\n",
    "        state_shape=state_shape,\n",
    "        num_actions=env.action_space.n,\n",
    "        learning_rate=config['dqn']['learning_rate'],\n",
    "        gamma=config['dqn']['gamma'],\n",
    "        epsilon_start=config['dqn']['epsilon_start'],\n",
    "        epsilon_end=config['dqn']['epsilon_end'],\n",
    "        epsilon_decay=config['dqn']['epsilon_decay'],\n",
    "        replay_buffer_size=config['dqn']['replay_buffer_size'],\n",
    "        batch_size=config['dqn']['batch_size'],\n",
    "        target_update_frequency=config['dqn']['target_update_frequency'],\n",
    "        hidden_sizes=config['dqn']['network'],\n",
    "        activation=config['dqn']['activation'],\n",
    "        state_representation=config['environment']['state_representation'],\n",
    "        device=device\n",
    "    )\n",
    "else:\n",
    "    agent = PPODiscreteAgent(\n",
    "        state_shape=state_shape,\n",
    "        num_actions=env.action_space.n,\n",
    "        learning_rate=config['ppo']['learning_rate'],\n",
    "        gamma=config['ppo']['gamma'],\n",
    "        gae_lambda=config['ppo']['gae_lambda'],\n",
    "        clip_epsilon=config['ppo']['clip_epsilon'],\n",
    "        value_coef=config['ppo']['value_coef'],\n",
    "        entropy_coef=config['ppo']['entropy_coef'],\n",
    "        max_grad_norm=config['ppo']['max_grad_norm'],\n",
    "        update_epochs=config['ppo']['update_epochs'],\n",
    "        batch_size=config['ppo']['batch_size'],\n",
    "        hidden_sizes=config['ppo']['network'],\n",
    "        activation=config['ppo']['activation'],\n",
    "        state_representation=config['environment']['state_representation'],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "# Load checkpoint\n",
    "try:\n",
    "    agent.load(checkpoint_path)\n",
    "    print(f\"✅ Agent loaded from {checkpoint_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading checkpoint: {e}\")\n",
    "    print(\"Using untrained agent (random actions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch agent play\n",
    "def watch_agent_play(env, agent, num_episodes=3, delay=0.1, max_steps=500):\n",
    "    \"\"\"\n",
    "    Watch trained agent play Snake game.\n",
    "    \n",
    "    Args:\n",
    "        env: Snake environment\n",
    "        agent: Trained agent\n",
    "        num_episodes: Number of episodes to watch\n",
    "        delay: Delay between frames (seconds)\n",
    "        max_steps: Maximum steps per episode\n",
    "    \"\"\"\n",
    "    agent.eval()\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state, info = env.reset()\n",
    "        done = False\n",
    "        steps = 0\n",
    "        total_reward = 0\n",
    "        \n",
    "        # Create figure for this episode\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Episode {episode + 1}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        while not done and steps < max_steps:\n",
    "            # Get action from agent\n",
    "            if isinstance(agent, DQNAgent):\n",
    "                action = agent.act(state, deterministic=True)\n",
    "            else:\n",
    "                action, _, _ = agent.act(state, deterministic=True)\n",
    "            \n",
    "            # Take step\n",
    "            next_state, reward, terminated, truncated, step_info = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            \n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "            state = next_state\n",
    "            \n",
    "            # Render current state\n",
    "            ax.clear()\n",
    "            ax.set_xlim(0, env.grid_size)\n",
    "            ax.set_ylim(0, env.grid_size)\n",
    "            ax.set_aspect('equal')\n",
    "            ax.invert_yaxis()\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            \n",
    "            # Draw grid\n",
    "            for i in range(env.grid_size):\n",
    "                for j in range(env.grid_size):\n",
    "                    rect = plt.Rectangle((j, i), 1, 1, \n",
    "                                       linewidth=0.5, edgecolor='lightgray', \n",
    "                                       facecolor='white', alpha=0.3)\n",
    "                    ax.add_patch(rect)\n",
    "            \n",
    "            # Draw snake\n",
    "            for i, segment in enumerate(env.snake):\n",
    "                row, col = segment\n",
    "                if i == 0:\n",
    "                    # Head\n",
    "                    color = '#2E7D32'\n",
    "                    alpha = 1.0\n",
    "                else:\n",
    "                    # Body\n",
    "                    color = '#66BB6A'\n",
    "                    alpha = 0.8 - (i / len(env.snake)) * 0.3\n",
    "                \n",
    "                rect = plt.Rectangle((col, row), 1, 1,\n",
    "                                   linewidth=1, edgecolor='darkgreen',\n",
    "                                   facecolor=color, alpha=alpha)\n",
    "                ax.add_patch(rect)\n",
    "            \n",
    "            # Draw food\n",
    "            if env.food:\n",
    "                row, col = env.food\n",
    "                circle = plt.Circle((col + 0.5, row + 0.5), 0.4,\n",
    "                                 color='red', alpha=0.8)\n",
    "                ax.add_patch(circle)\n",
    "            \n",
    "            # Add info text\n",
    "            info_text = (f\"Episode {episode + 1} | \"\n",
    "                        f\"Score: {env.score} | \"\n",
    "                        f\"Steps: {steps} | \"\n",
    "                        f\"Length: {len(env.snake)} | \"\n",
    "                        f\"Reward: {total_reward:.1f}\")\n",
    "            ax.text(0.5, -0.05, info_text,\n",
    "                   transform=ax.transAxes, ha='center',\n",
    "                   fontsize=12, fontweight='bold')\n",
    "            \n",
    "            ax.set_title('Snake Game - Trained Agent', fontsize=16, fontweight='bold')\n",
    "            \n",
    "            # Display\n",
    "            plt.tight_layout()\n",
    "            display(fig)\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            time.sleep(delay)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        # Final results\n",
    "        print(f\"\\nEpisode {episode + 1} Complete!\")\n",
    "        print(f\"  Final Score: {env.score}\")\n",
    "        print(f\"  Total Steps: {steps}\")\n",
    "        print(f\"  Total Reward: {total_reward:.2f}\")\n",
    "        print(f\"  Snake Length: {len(env.snake)}\")\n",
    "        \n",
    "        plt.close(fig)\n",
    "    \n",
    "    agent.train()\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"All episodes complete!\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "# Run it!\n",
    "watch_agent_play(env, agent, num_episodes=3, delay=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
